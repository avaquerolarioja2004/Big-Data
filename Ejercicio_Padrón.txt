1.

1.1.
hive
hive> create database datos_padron;
hive> use datos_padron;

1.2. 
CREATE TABLE padron_txt (
  COD_DISTRITO INT,
  DESC_DISTRITO STRING,
  COD_DIST_BARRIO INT,
  DESC_BARRIO STRING,
  COD_BARRIO INT,
  COD_DIST_SECCION INT,
  COD_SECCION INT,
  COD_EDAD_INT STRING,
  ESPANOLESHOMBRES INT,
  ESPANOLESMUJERES INT,
  EXTRANJEROSHOMBRES INT,
  EXTRANJEROSMUJERES INT,
  FX_CARGA STRING,
  FX_DATOS_INI STRING,
  FX_DATOS_FIN STRING
)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES (
  "separatorChar" = "\;",
  "quoteChar"     = "\""
)
STORED AS TEXTFILE
TBLPROPERTIES (
  "skip.header.line.count"="1"
);

LOAD DATA LOCAL INPATH '/home/cloudera/Desktop/hgfs/Padrón/estadisticas202402.csv' OVERWRITE INTO TABLE padron_txt;

1.3.
insert overwrite local directory '/home/cloudera/Desktop/hgfs/Padrón/tablaTxt2'
SELECT
  COD_DISTRITO,
  TRIM(DESC_DISTRITO) AS DESC_DISTRITO,
  COD_DIST_BARRIO,
  TRIM(DESC_BARRIO) AS DESC_BARRIO,
  COD_BARRIO,
  COD_DIST_SECCION,
  COD_SECCION,
  TRIM(COD_EDAD_INT) AS COD_EDAD_INT,
  ESPANOLESHOMBRES,
  ESPANOLESMUJERES,
  EXTRANJEROSHOMBRES,
  EXTRANJEROSMUJERES,
  TRIM(FX_CARGA) AS FX_CARGA,
  TRIM(FX_DATOS_INI) AS FX_DATOS_INI,
  TRIM(FX_DATOS_FIN) AS FX_DATOS_FIN
FROM
  padron_txt;

1.4.
- La diferencia es obvia, si incluimos la palabra local en vez de buscar el archivo en hdfs, realizará la busqueda en nuestro equipo.


1.5.
-- Esto debería de realizar el cambio, pero como el csv que uso no contiene nulos/'' en su contenido en las columnas especificadas, crea una tabla identica.

SELECT
  COUNT(*) AS total_filas,
  SUM(
    CASE
      WHEN ESPANOLESHOMBRES = '' OR ESPANOLESMUJERES = '' OR EXTRANJEROSHOMBRES = '' OR EXTRANJEROSMUJERES = '' THEN 1
      ELSE 0
    END
  ) AS filas_con_espacios
FROM
  padron_txt;

CREATE TABLE padron_txt_limpio AS
SELECT
  COD_DISTRITO,
  DESC_DISTRITO,
  COD_DIST_BARRIO,
  DESC_BARRIO,
  COD_BARRIO,
  COD_DIST_SECCION,
  COD_SECCION,
  COD_EDAD_INT,
  CASE WHEN ESPANOLESHOMBRES = '' THEN 0 ELSE CAST(ESPANOLESHOMBRES AS INT) END AS ESPANOLESHOMBRES,
  CASE WHEN ESPANOLESMUJERES = '' THEN 0 ELSE CAST(ESPANOLESMUJERES AS INT) END AS ESPANOLESMUJERES,
  CASE WHEN EXTRANJEROSHOMBRES = '' THEN 0 ELSE CAST(EXTRANJEROSHOMBRES AS INT) END AS EXTRANJEROSHOMBRES,
  CASE WHEN EXTRANJEROSMUJERES = '' THEN 0 ELSE CAST(EXTRANJEROSMUJERES AS INT) END AS EXTRANJEROSMUJERES,
  FX_CARGA,
  FX_DATOS_INI,
  FX_DATOS_FIN
FROM
padron_txt;


1.6.

- El regex seria el siguiente, el prblema es que no consigo implementarlo al codigo de creación de la tabla:

'^([0-9]+);\"([^\"]*)\";([0-9]+);\"([^\"]*)\";([0-9]+);([0-9]+);([0-9]+);\"([^\"]*)\";([0-9]+);([0-9]+);([0-9]+);([0-9]+);\"([^\"]*)\";\"([^\"]*)\";\"([^\"]*)\"$'

hive> CREATE TABLE padron_txt_2 (
    >     COD_DISTRITO INT,
    >     DESC_DISTRITO STRING,
    >     COD_DIST_BARRIO INT,
    >     DESC_BARRIO STRING,
    >     COD_BARRIO INT,
    >     COD_DIST_SECCION INT,
    >     COD_SECCION INT,
    >     COD_EDAD_INT STRING,
    >     ESPANOLESHOMBRES INT,
    >     ESPANOLESMUJERES INT,
    >     EXTRANJEROSHOMBRES INT,
    >     EXTRANJEROSMUJERES INT,
    >     FX_CARGA STRING,
    >     FX_DATOS_INI STRING,
    >     FX_DATOS_FIN STRING
    > )
    > ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe' 
    > WITH SERDEPROPERTIES ('input.regex'='^([0-9]+);\"([^\"]*)\";([0-9]+);\"([^\"]*)\";([0-9]+);([0-9]+);([0-9]+);\"([^\"]*)\";([0-9]+);([0-9]+);([0-9]+);([0-9]+);\"([^\"]*)\";\"([^\"]*)\";\"([^\"]*)\")');
MismatchedTokenException(6!=307)
	at org.antlr.runtime.BaseRecognizer.recoverFromMismatchedToken(BaseRecognizer.java:617)
	at org.antlr.runtime.BaseRecognizer.match(BaseRecognizer.java:115)
	at org.apache.hadoop.hive.ql.parse.HiveParser.keyValueProperty(HiveParser.java:35287)
	at org.apache.hadoop.hive.ql.parse.HiveParser.tablePropertiesList(HiveParser.java:35057)
	at org.apache.hadoop.hive.ql.parse.HiveParser.tableProperties(HiveParser.java:34920)
	at org.apache.hadoop.hive.ql.parse.HiveParser.rowFormatSerde(HiveParser.java:34296)
	at org.apache.hadoop.hive.ql.parse.HiveParser.tableRowFormat(HiveParser.java:34761)
	at org.apache.hadoop.hive.ql.parse.HiveParser.createTableStatement(HiveParser.java:5196)
	at org.apache.hadoop.hive.ql.parse.HiveParser.ddlStatement(HiveParser.java:2557)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1589)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1065)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:201)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:522)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1356)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1473)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1285)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1275)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:226)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:175)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:389)
	at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:781)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:634)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
FAILED: ParseException line 19:37 mismatched input '^' expecting StringLiteral near '=' in specifying key/value property

2.

2.1.
- CTAS significa Create Table As Selected, que como su nombre indica te crea una nueva tabla habiendo hecho un select de otra tabla.

2.2.
CREATE TABLE padron_parquet
STORED AS PARQUET
AS
SELECT
    COD_DISTRITO,
    DESC_DISTRITO,
    COD_DIST_BARRIO,
    DESC_BARRIO,
    COD_BARRIO,
    COD_DIST_SECCION,
    COD_SECCION,
    COD_EDAD_INT,
    ESPANOLESHOMBRES,
    ESPANOLESMUJERES,
    EXTRANJEROSHOMBRES,
    EXTRANJEROSMUJERES,
    FX_CARGA,
    FX_DATOS_INI,
    FX_DATOS_FIN
FROM
    padron_txt;

2.3.
CREATE TABLE padron_parquet_2
STORED AS PARQUET
AS
SELECT
    COD_DISTRITO,
    DESC_DISTRITO,
    COD_DIST_BARRIO,
    DESC_BARRIO,
    COD_BARRIO,
    COD_DIST_SECCION,
    COD_SECCION,
    COD_EDAD_INT,
    ESPANOLESHOMBRES,
    ESPANOLESMUJERES,
    EXTRANJEROSHOMBRES,
    EXTRANJEROSMUJERES,
    FX_CARGA,
    FX_DATOS_INI,
    FX_DATOS_FIN
FROM
    padron_txt_2;


2.5.
- Parquet es como organizar datos en columnas en lugar de filas, haciendo que ocupen menos espacio y las búsquedas sean más rápidas. Además, es flexible para cambios en la información.

2.6.
hive -e "SHOW CREATE TABLE datos_padron.padron_txt"
hive -e "SHOW CREATE TABLE datos_padron.padron_txt_2"
hdfs dfs -du /ruta_de_padron_txt
hdfs dfs -du /ruta_de_padron_txt_2


hive -e "SHOW CREATE TABLE datos_padron.padron_parquet"
hive -e "SHOW CREATE TABLE datos_padron.padron_parquet_2"
hdfs dfs -du /ruta_de_padron_parquet
hdfs dfs -du /ruta_de_padron_parquet_2

3.

3.1
- Impala es el único motor de consultas SQL de procesamiento masivo en paralelo con portabilidad híbrida, diseñado para trabajar con datos almacenados en plataformas de datos de código abierto, como el sistema de archivos HDFS de Apache Hadoop

3.2.
- En la velocidad de las consultas y en la fiabilidad de las mismas, por el segundo motivo hive es más seguro pero más lento. En cambio impala ante fallos tendrá que volver a lanzarse la consulta.

3.3.
- La función que realiza ese comando es de indicar a Hive que esos datos estan obsoletos para que la próxima vez los recargue de cero.

3.4.
use datos_padron;
INVALIDATE METADATA;
REFRESH;

3.5.
SELECT
    DESC_DISTRITO,
    DESC_BARRIO,
    SUM(ESPANOLESHOMBRES) AS Total_EspanolesHombres,
    SUM(ESPANOLESMUJERES) AS Total_EspanolesMujeres,
    SUM(EXTRANJEROSHOMBRES) AS Total_ExtranjerosHombres,
    SUM(EXTRANJEROSMUJERES) AS Total_ExtranjerosMujeres
FROM
    padron_txt_nueva
GROUP BY
    DESC_DISTRITO,
    DESC_BARRIO;
Query: select DESC_DISTRITO,
    DESC_BARRIO,
    SUM(ESPANOLESHOMBRES) AS Total_EspanolesHombres,
    SUM(ESPANOLESMUJERES) AS Total_EspanolesMujeres,
    SUM(EXTRANJEROSHOMBRES) AS Total_ExtranjerosHombres,
    SUM(EXTRANJEROSMUJERES) AS Total_ExtranjerosMujeres
FROM
    padron_txt
GROUP BY
    DESC_DISTRITO,
    DESC_BARRIO;


3.6-3.7.
- Lo unico que puedo añadir es que hay que tener cuidado con las funciones extra que lleva la tabla, ya que por ejemplo me ha dado este error al intentar hacer consultas sobre una tabla: Impala does not support tables of this type. REASON: SerDe library 'org.apache.hadoop.hive.serde2.OpenCSVSerde' is not supported.
- Y otro punto a recalcar es la velocidad de las consultas, desde hive es 10 veces más lenta la consulta.

3.8.
Si, una bastante grande la diferencia de tiempo.


4.

4.1
CREATE TABLE padron_particionado (
  COD_DISTRITO INT,
  COD_DIST_BARRIO INT,
  COD_BARRIO INT,
  COD_DIST_SECCION INT,
  COD_SECCION INT,
  COD_EDAD_INT STRING,
  ESPANOLESHOMBRES INT,
  ESPANOLESMUJERES INT,
  EXTRANJEROSHOMBRES INT,
  EXTRANJEROSMUJERES INT,
  FX_CARGA STRING,
  FX_DATOS_INI STRING,
  FX_DATOS_FIN STRING
)
PARTITIONED BY (DESC_DISTRITO STRING, DESC_BARRIO STRING)
STORED AS PARQUET;

4.2.
SET hive.exec.dynamic.partition.mode=nonstrict;
SET hive.exec.max.dynamic.partitions=2000;
SET hive.exec.max.dynamic.partitions.pernode=200;

INSERT OVERWRITE TABLE padron_particionado
PARTITION (DESC_DISTRITO, DESC_BARRIO)
SELECT
  COD_DISTRITO,
  COD_DIST_BARRIO,
  COD_BARRIO,
  COD_DIST_SECCION,
  COD_SECCION,
  COD_EDAD_INT,
  ESPANOLESHOMBRES,
  ESPANOLESMUJERES,
  EXTRANJEROSHOMBRES,
  EXTRANJEROSMUJERES,
  FX_CARGA,
  FX_DATOS_INI,
  FX_DATOS_FIN,
  trim(DESC_DISTRITO) as dis,
  trim(DESC_BARRIO) as barr
FROM
  padron_parquet_2;

show partitions padron_particionado;

4.3
impala-shell
invalidate metadata datos_padron.padron_particionado;

4.4
SELECT
  DESC_DISTRITO,
  DESC_BARRIO,
  SUM(ESPANOLESHOMBRES) AS TotalEspanolesHombres,
  SUM(ESPANOLESMUJERES) AS TotalEspanolesMujeres,
  SUM(EXTRANJEROSHOMBRES) AS TotalExtranjerosHombres,
  SUM(EXTRANJEROSMUJERES) AS TotalExtranjerosMujeres
FROM
  padron_txt
WHERE
  trim(DESC_DISTRITO) = 'CENTRO' or trim(DESC_DISTRITO)= 'LATINA' or trim(DESC_DISTRITO)= 'CHAMARTIN' or trim(DESC_DISTRITO)= 'TETUAN' or trim(DESC_DISTRITO)= 'VICALVARO' or trim(DESC_DISTRITO)= 'BARAJAS'
GROUP BY
  DESC_DISTRITO,
  DESC_BARRIO;

4.5-4.6-4.7.
- La organización y velocidad de la consulta de la tabla particionada es superior.

5.

5.1.



